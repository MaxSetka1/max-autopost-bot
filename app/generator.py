# app/generator.py
from __future__ import annotations

import os, json, re
from typing import Dict, List, Any

from app.retriever import search_book
from app.gpt import _client
from app.sheets import get_book_meta  # <-- –±–µ—Ä—ë–º meta –∏–∑ –ª–∏—Å—Ç–∞ books

MODEL_SUMMARY = os.getenv("OPENAI_MODEL_SUMMARY", "gpt-4o-mini")
MODEL_POSTS   = os.getenv("OPENAI_MODEL_POSTS",   "gpt-4o-mini")

_SUMMARY_CACHE: Dict[str, Dict[str, Any]] = {}

# ---------- –£—Ç–∏–ª–∏—Ç—ã ----------
def _clean_bold(s: str) -> str:
    return s.replace("**", "").strip()

def _squash_blanks(s: str) -> str:
    return re.sub(r"\n{3,}", "\n\n", s).strip()

def _normalize(s: str) -> str:
    return _squash_blanks(_clean_bold(s))

def _book_info(s: Dict[str, Any], book_id: str, channel_name: str) -> tuple[str, str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (title, author) –≤ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–µ:
    1) –ª–∏—Å—Ç 'books' (–µ—Å–ª–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ)
    2) –ø–æ–ª—è –∏–∑ summary.about
    3) fallback –ø–æ book_id
    """
    # 1) –∏–∑ —Ç–∞–±–ª–∏—Ü—ã books
    meta = get_book_meta(book_id) if book_id else {"title":"", "author":""}
    title = (meta.get("title") or "").strip()
    author = (meta.get("author") or "").strip()

    # 2) –∏–∑ summary.about
    about = s.get("about") or {}
    if not title:
        t = (about.get("title") or "").strip()
        if t:
            title = t
    if not author:
        a = (about.get("author") or "").strip()
        if a:
            author = a

    # 3) fallback –ø–æ id/–∫–∞–Ω–∞–ª—É
    if not title:
        title = (book_id.replace("_", " ").strip().title() if book_id else channel_name)

    return title, author

# ---------- –°–±–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –∫–Ω–∏–≥–∏ ----------
def _collect_context(book_id: str) -> str:
    queries = [
        "–æ—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è –∫–Ω–∏–≥–∏ –≤ —Ü–µ–ª–æ–º",
        "–∫–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –∏ –ø—Ä–∞–≤–∏–ª–∞ –∞–≤—Ç–æ—Ä–∞",
        "–ø–æ—à–∞–≥–æ–≤—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è",
        "–ø—Ä–∏–º–µ—Ä—ã –∏ –∫–µ–π—Å—ã –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è",
        "—Å–∏–ª—å–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã –∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏",
        "–¥–ª—è –∫–æ–≥–æ –∫–Ω–∏–≥–∞ –∏ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª—ã",
    ]
    chunks, seen = [], set()
    for q in queries:
        for ch in search_book(book_id, q, top_k=10):
            t = (ch.get("text") or "").strip()
            if t and t not in seen:
                seen.add(t)
                chunks.append(t)
            if len(chunks) >= 60:
                break
        if len(chunks) >= 60:
            break
    joined = "\n\n".join(chunks)
    return joined[:40_000] if len(joined) > 40_000 else joined

# ---------- –ö–æ–Ω—Å–ø–µ–∫—Ç ----------
def _ask_json_summary(context: str, book_id: str, channel_name: str) -> Dict[str, Any]:
    system = "–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä –¥–µ–ª–æ–≤–æ–≥–æ Telegram-–∫–∞–Ω–∞–ª–∞. –°–¥–µ–ª–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –ø—Ä–∏–∫–ª–∞–¥–Ω–æ–π –∫–æ–Ω—Å–ø–µ–∫—Ç –∫–Ω–∏–≥–∏. –†—É—Å—Å–∫–∏–π —è–∑—ã–∫."
    user = f"""
–ù–∞ –≤—Ö–æ–¥–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∫–Ω–∏–≥–∏. –°–¥–µ–ª–∞–π JSON-–∫–æ–Ω—Å–ø–µ–∫—Ç:

{{
  "about": {{"title":"","author":"","thesis":"","audience":""}},
  "key_ideas": ["..."],
  "practices": [{{"name":"","steps":["—à–∞–≥ 1","—à–∞–≥ 2"]}}],
  "cases": ["..."],
  "quotes": [{{"text":"","note":""}}],
  "reflection": ["..."]
}}

–ù–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã ‚Äî –µ—Å–ª–∏ —á–µ–≥–æ-—Ç–æ –Ω–µ—Ç, –æ—Å—Ç–∞–≤—å –ø—É—Å—Ç—ã–º.
–í–æ–∑–≤—Ä–∞—â–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π.

–§—Ä–∞–≥–º–µ–Ω—Ç—ã:
---
{context}
---
"""
    resp = _client().chat.completions.create(
        model=MODEL_SUMMARY,
        messages=[{"role":"system","content":system},
                  {"role":"user","content":user}],
        temperature=0.2,
        response_format={"type":"json_object"},
    )
    try:
        return json.loads(resp.choices[0].message.content)
    except Exception:
        return {
            "about":{"title":"","author":"","thesis":"","audience":""},
            "key_ideas":[],"practices":[],"cases":[],"quotes":[],"reflection":[]
        }

def _ensure_summary(book_id: str, channel_name: str) -> Dict[str, Any]:
    if book_id in _SUMMARY_CACHE:
        return _SUMMARY_CACHE[book_id]
    ctx = _collect_context(book_id)
    summary = _ask_json_summary(ctx, book_id, channel_name)
    _SUMMARY_CACHE[book_id] = summary
    return summary

# ---------- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–æ–≤ ----------
def _gen_with_prompt(fmt: str, summary: Dict[str, Any], *, book_id: str, channel_name: str) -> str:
    base = json.dumps(summary, ensure_ascii=False, indent=2)
    title, author = _book_info(summary, book_id, channel_name)

    prompts = {
        "announce": (
            "–°–¥–µ–ª–∞–π –∞–Ω–æ–Ω—Å –∫–Ω–∏–≥–∏ –¥–ª—è Telegram.\n"
            "- –ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ ¬´–∑–∞—á–µ–º —á–∏—Ç–∞—Ç—å¬ª (1 —Ñ—Ä–∞–∑–∞),\n"
            "- ¬´–∫–æ–º—É –æ—Å–æ–±–µ–Ω–Ω–æ –ø–æ–ª–µ–∑–Ω–∞¬ª,\n"
            "- –∫—Ä—é—á–æ–∫: 1 —è—Ä–Ω–∞—è —Ü–∏—Ñ—Ä–∞/–ø—Ä–∏–º–µ—Ä –∏–∑ –∫–Ω–∏–≥–∏ (–±–µ–∑ –≤–æ–¥—ã),\n"
            "- 3‚Äì4 –ª–∞–∫–æ–Ω–∏—á–Ω—ã—Ö –±—É–ª–ª–µ—Ç–∞, 2‚Äì3 —É–º–µ—Å—Ç–Ω—ã—Ö —ç–º–æ–¥–∑–∏.\n"
            "–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∂–∏—Ä–Ω–æ–µ (**). –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–Ω–∏–≥–∏ ‚Äî –∑–∞–≥–æ–ª–æ–≤–æ–∫ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –æ—Ç–¥–µ–ª—å–Ω–æ."
        ),
        "insight": (
            "–í—ã–¥–µ–ª–∏ 3‚Äì5 –∫–ª—é—á–µ–≤—ã—Ö –∏–¥–µ–π –∏–∑ –∫–Ω–∏–≥–∏. –ö–∞–∂–¥–∞—è –∏–¥–µ—è: 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è + –∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–∏–º–µ—Ä/–ø–æ—è—Å–Ω–µ–Ω–∏–µ.\n"
            "–°—Ç–∏–ª—å: –ª–∞–∫–æ–Ω–∏—á–Ω–æ, —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ, 1‚Äì2 —ç–º–æ–¥–∑–∏ —Å—É–º–º–∞—Ä–Ω–æ. –ë–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ. –ó–∞–≥–æ–ª–æ–≤–æ–∫ –º—ã –¥–æ–±–∞–≤–∏–º —Å–∞–º–∏."
        ),
        "practice": (
            "–í—ã–±–µ—Ä–∏ 1 –ø—Ä–∞–∫—Ç–∏–∫—É –∏ –æ–ø–∏—à–∏ –ø–æ—à–∞–≥–æ–≤–æ: 4‚Äì6 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —à–∞–≥–æ–≤.\n"
            "–î–æ–±–∞–≤—å –±—ã—Ç–æ–≤–æ–π –ø—Ä–∏–º–µ—Ä –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è.\n"
            "–°—Ç–∏–ª—å: –ø—Ä–æ—Å—Ç–æ–π —è–∑—ã–∫, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, 1‚Äì2 —ç–º–æ–¥–∑–∏. –ë–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ. –ó–∞–≥–æ–ª–æ–≤–æ–∫ –º—ã –¥–æ–±–∞–≤–∏–º —Å–∞–º–∏."
        ),
        "case": (
            "–û–ø–∏—à–∏ 1 —Ä–µ–∞–ª—å–Ω—ã–π –∫–µ–π—Å –∏–∑ –∫–Ω–∏–≥–∏ –≤ 3‚Äì5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö: –∫—Ç–æ/–∫–æ–≥–¥–∞/—á—Ç–æ —Å–¥–µ–ª–∞–ª–∏/—Ä–µ–∑—É–ª—å—Ç–∞—Ç.\n"
            "–ü–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —É–ø–æ–º—è–Ω–∏ –Ω–∞–∑–≤–∞–Ω–∏—è/–∏–º–µ–Ω–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å –≤ –∫–æ–Ω—Å–ø–µ–∫—Ç–µ). –î–æ–±–∞–≤—å –≤—ã–≤–æ–¥: —á–µ–º—É —ç—Ç–æ —É—á–∏—Ç. 0‚Äì1 —ç–º–æ–¥–∑–∏. –ë–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ."
        ),
        "quote": (
            "–í—ã–±–µ—Ä–∏ 1 —Å–∏–ª—å–Ω—É—é —Ü–∏—Ç–∞—Ç—É –∏–∑ –∫–Ω–∏–≥–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å). –ü—Ä–∏–≤–µ–¥–∏ –¥–æ—Å–ª–æ–≤–Ω–æ –≤ –∫–∞–≤—ã—á–∫–∞—Ö –∏ –¥–æ–±–∞–≤—å 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ—è—Å–Ω–µ–Ω–∏—è: –∫–∞–∫ –ø—Ä–∏–º–µ–Ω–∏—Ç—å.\n"
            "–ë–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ, 0‚Äì1 —ç–º–æ–¥–∑–∏."
        ),
        "reflect": (
            "–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π 2 –æ—Å—Ç—Ä—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏, —á—Ç–æ–±—ã —á–∏—Ç–∞—Ç–µ–ª—å –ø—Ä–∏–º–µ–Ω–∏–ª –∏–¥–µ—é –∫ —Å–µ–±–µ. –î–µ–ª–∞–π –≤–æ–ø—Ä–æ—Å—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –∏ –ø—Ä–æ–≤–æ–∫–∞—Ü–∏–æ–Ω–Ω—ã–º–∏.\n"
            "–ö–æ—Ä–æ—Ç–∫–æ, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, 0‚Äì1 —ç–º–æ–¥–∑–∏. –ë–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ."
        ),
    }
    prompt = prompts.get(fmt, "–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫—É—é –≤—ã–∂–∏–º–∫—É –∏–∑ –∫–Ω–∏–≥–∏ –±–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ –∏ –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞.")

    resp = _client().chat.completions.create(
        model=MODEL_POSTS,
        messages=[
            {"role":"system","content":"–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä Telegram-–∫–∞–Ω–∞–ª–∞: –ø–∏—à–∏ —è—Ä–∫–æ, –ø–æ –¥–µ–ª—É, —Å –ª—ë–≥–∫–∏–º–∏ —ç–º–æ–¥–∑–∏ –∏ –±–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ –≤—ã–¥–µ–ª–µ–Ω–∏—è."},
            {"role":"user","content":f"–ö–æ–Ω—Å–ø–µ–∫—Ç –∫–Ω–∏–≥–∏:\n{base}\n\n–ó–∞–¥–∞—á–∞:\n{prompt}"}
        ],
        temperature=0.7,
    )
    body = _normalize(resp.choices[0].message.content or "")

    # –ó–∞–≥–æ–ª–æ–≤–∫–∏/—Ö—ç—à—Ç–µ–≥–∏
    map_emoji = {
        "announce": "üìö",
        "insight":  "üí°",
        "practice": "üõ†Ô∏è",
        "case":     "üìå",
        "quote":    "üó£Ô∏è",
        "reflect":  "üß≠",
    }
    map_tag = {
        "announce": "#–∞–Ω–æ–Ω—Å #–∫–Ω–∏–≥–∞",
        "insight":  "#–∏–Ω—Å–∞–π—Ç",
        "practice": "#–ø—Ä–∞–∫—Ç–∏–∫–∞",
        "case":     "#–∫–µ–π—Å",
        "quote":    "#—Ü–∏—Ç–∞—Ç–∞",
        "reflect":  "#—Ä–µ—Ñ–ª–µ–∫—Å–∏—è",
    }
    map_label = {
        "announce": "–ö–Ω–∏–≥–∞ –¥–Ω—è",
        "insight":  "–∫–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏",
        "practice": "–ø—Ä–∞–∫—Ç–∏–∫–∞",
        "case":     "–∫–µ–π—Å",
        "quote":    "—Ü–∏—Ç–∞—Ç–∞",
        "reflect":  "–≤–æ–ø—Ä–æ—Å –¥–Ω—è",
    }

    emoji = map_emoji.get(fmt, "üìù")
    label = map_label.get(fmt, fmt)
    tags  = map_tag.get(fmt, "#—Å–≤–æ–¥–∫–∞")

    # –∑–∞–≥–æ–ª–æ–≤–æ–∫: –¥–ª—è announce –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å –∞–≤—Ç–æ—Ä–æ–º
    if fmt == "announce":
        by = f" ‚Äî {author}" if author else ""
        header = f"{emoji} {label} ‚Äî {title}{by}"
    else:
        header = f"{emoji} {title} ‚Äî {label.capitalize()}"

    final = f"{header}\n\n{body}\n\n{tags}"
    return final.strip()

# ---------- –ü—É–±–ª–∏—á–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ----------
def generate_from_book(channel_name: str, book_id: str, fmt: str) -> str:
    s = _ensure_summary(book_id, channel_name)
    return _gen_with_prompt(fmt.lower(), s, book_id=book_id, channel_name=channel_name)

def generate_by_format(fmt: str, items: List[dict]) -> str:
    f = (fmt or "").lower()
    if f == "quote":
        return "¬´–í—ã ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–æ–≥–æ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç–µ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å¬ª. #—Ü–∏—Ç–∞—Ç–∞"
    if f == "practice":
        return "–ü—Ä–∞–∫—Ç–∏–∫–∞ –Ω–µ–¥–µ–ª–∏: –ø—Ä–∞–≤–∏–ª–æ 2 –º–∏–Ω—É—Ç. #–ø—Ä–∞–∫—Ç–∏–∫–∞"
    return "–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –≥–æ—Ç–æ–≤—è—Ç—Å—è. #—Å–≤–æ–¥–∫–∞"
