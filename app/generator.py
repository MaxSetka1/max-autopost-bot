# app/generator.py
from __future__ import annotations

import os, json, re
from typing import Dict, List, Any

from app.retriever import search_book
from app.gpt import _client
from app.sheets import get_book_meta  # –∞–≤—Ç–æ—Ä/–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ –ª–∏—Å—Ç–∞ books

MODEL_SUMMARY = os.getenv("OPENAI_MODEL_SUMMARY", "gpt-4o-mini")
MODEL_POSTS   = os.getenv("OPENAI_MODEL_POSTS",   "gpt-4o-mini")

_SUMMARY_CACHE: Dict[str, Dict[str, Any]] = {}

# ---------- –£—Ç–∏–ª–∏—Ç—ã ----------

def _clean_bold(s: str) -> str:
    return s.replace("**", "").strip()

def _squash_blanks(s: str) -> str:
    s = re.sub(r"[ \t]+\n", "\n", s)          # —Ö–≤–æ—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–±–µ–ª—ã –≤ –∫–æ–Ω—Ü–∞—Ö —Å—Ç—Ä–æ–∫
    s = re.sub(r"\n{3,}", "\n\n", s).strip()  # –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    return s

def _normalize(s: str) -> str:
    s = _clean_bold(s)
    s = re.sub(r"!{3,}", "!!", s)  # —É–º–µ—Ä—è–µ–º ¬´!!!¬ª
    return _squash_blanks(s)

def _deslug(s: str) -> str:
    # –£–±–∏—Ä–∞–µ–º .pdf/.docx, –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è, –º—É—Å–æ—Ä–Ω—ã–µ —Å—É—Ñ—Ñ–∏–∫—Å—ã
    s = re.sub(r"\.(pdf|docx?|rtf|txt|epub)$", "", s, flags=re.I)
    s = s.replace("_", " ")
    # –µ—Å–ª–∏ –≤—Å—ë –ª–∞—Ç–∏–Ω–∏—Ü–µ–π –∏ –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤ ‚Äî –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º slug ‚Üí —Å—Ç–∞–≤–∏–º –ø—Ä–æ–±–µ–ª—ã –ø–æ –¥–µ—Ñ–∏—Å–∞–º/–∫–∞–ø—Å–∞–º
    s = re.sub(r"[-]+", " ", s)
    s = re.sub(r"([a-z])([A-Z])", r"\1 \2", s)
    s = re.sub(r"\s{2,}", " ", s).strip()
    return s

def _beautify_quotes(s: str) -> str:
    # –ø—Ä—è–º—ã–µ –∫–∞–≤—ã—á–∫–∏ -> ¬´—ë–ª–æ—á–∫–∏¬ª (–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ, —Ç–æ–ª—å–∫–æ –≤–æ–∫—Ä—É–≥ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ü–∏—Ç–∞—Ç –≤ –Ω–∞—á–∞–ª–µ/–≤ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏)
    s = re.sub(r'(^|\s)"([^"\n]{3,200})"(\s|$)', r'\1¬´\2¬ª\3', s)
    return s

_EMOJI_RE = re.compile(
    r"([\U0001F1E6-\U0001F1FF]|"   # —Ñ–ª–∞–≥–∏
    r"[\U0001F300-\U0001F5FF]|"    # —Å–∏–º–≤–æ–ª—ã –∏ –ø–∏–∫—Ç–æ–≥—Ä–∞–º–º—ã
    r"[\U0001F600-\U0001F64F]|"    # —Å–º–∞–π–ª–∏–∫–∏
    r"[\U0001F680-\U0001F6FF]|"    # —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ —Ç.–ø.
    r"[\U00002600-\U000026FF]|"    # —Ä–∞–∑–Ω–æ–µ
    r"[\U00002700-\U000027BF])"    # —Ä–∞–∑–Ω–æ–µ
)

def _limit_emojis(body: str, max_count: int) -> str:
    # –æ—Å—Ç–∞–≤–∏–º –ø–µ—Ä–≤—ã–µ N —ç–º–æ–¥–∑–∏, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –≤—ã–ø–∏–ª–∏–º
    out, cnt = [], 0
    for ch in body:
        if _EMOJI_RE.match(ch):
            if cnt < max_count:
                out.append(ch); cnt += 1
            else:
                # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ª–∏—à–Ω–∏–µ —ç–º–æ–¥–∑–∏
                continue
        else:
            out.append(ch)
    # –Ω–µ –¥–æ–ø—É—Å–∫–∞–µ–º —ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–µ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏ –ø–æ–¥—Ä—è–¥
    s = "".join(out)
    s = re.sub(r"(?m)^[\s]*(" + _EMOJI_RE.pattern + r")\s*", r"\1 ", s)
    return s

_STOP_START = (
    r"^(–•–æ—Ç–∏—Ç–µ|–ì–æ—Ç–æ–≤—ã|–ó–Ω–∞–µ—Ç–µ –ª–∏ –≤—ã|–ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ|–í –æ–¥–Ω–æ–π –∏–∑ –≥–ª–∞–≤|–ê–≤—Ç–æ—Ä —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç)",
)

def _declickbait(text: str) -> str:
    # —É–±–∏—Ä–∞–µ–º –∫–ª–∏–∫–±–µ–π—Ç–Ω—ã–µ –∑–∞—Ö–æ–¥—ã –≤ –Ω–∞—á–∞–ª–µ –∞–±–∑–∞—Ü–µ–≤
    text = re.sub(r"(?m)" + _STOP_START + r".{0,80}\?\s*", "", text)
    # –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º ¬´–≤ –æ–¥–Ω–æ–π –∏–∑ –≥–ª–∞–≤/–≤ 2020 –≥–æ–¥—É –∫–æ–º–ø–∞–Ω–∏—è...¬ª
    text = re.sub(r"(?mi)^–≤ –æ–¥–Ω–æ–π –∏–∑ –≥–ª–∞–≤[^.\n]*\.\s*", "", text)
    text = re.sub(r"(?mi)^–≤ \d{4} –≥–æ–¥—É –∫–æ–º–ø–∞–Ω–∏—è[^.\n]*\.\s*", "", text)
    return text

def _emoji_budget_for_length(s: str) -> int:
    n = len(s)
    if n < 400:  return 1
    if n < 800:  return 2
    return 3

# ---------- –ù–∞–∑–≤–∞–Ω–∏–µ / –ê–≤—Ç–æ—Ä ----------

def _book_title(summary: Dict[str, Any], book_id: str, channel_name: str) -> str:
    """–ù–∞–∑–≤–∞–Ω–∏–µ: —Å–Ω–∞—á–∞–ª–∞ –∏–∑ –∫–æ–Ω—Å–ø–µ–∫—Ç–∞, –∑–∞—Ç–µ–º –∏–∑ –ª–∏—Å—Ç–∞ books, –∏–Ω–∞—á–µ ‚Äî –æ—á–∏—â–µ–Ω–Ω—ã–π id."""
    about = summary.get("about") or {}
    t = (about.get("title") or "").strip()
    if not t:
        try:
            meta = get_book_meta(book_id)
            t = (meta.get("title") or "").strip()
        except Exception:
            t = ""
    if not t:
        t = _deslug(book_id or channel_name)
    # –∫–æ—Å–º–µ—Ç–∏–∫–∞
    t = re.sub(r"\s+-\s+$", "", t)
    t = _beautify_quotes(t)
    return t

def _book_author(summary: Dict[str, Any], book_id: str) -> str:
    """–ê–≤—Ç–æ—Ä ‚Äî —Å–Ω–∞—á–∞–ª–∞ –∏–∑ –∫–æ–Ω—Å–ø–µ–∫—Ç–∞, –∑–∞—Ç–µ–º –∏–∑ –ª–∏—Å—Ç–∞ books (–Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–µ–º)."""
    about = summary.get("about") or {}
    author = (about.get("author") or "").strip()
    if author:
        return author
    try:
        meta = get_book_meta(book_id)
        author = (meta.get("author") or "").strip()
    except Exception:
        author = ""
    return author

# ---------- –°–±–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ----------

def _collect_context(book_id: str) -> str:
    queries = [
        "–æ—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è –∫–Ω–∏–≥–∏ –≤ —Ü–µ–ª–æ–º",
        "–∫–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –∏ –ø—Ä–∞–≤–∏–ª–∞ –∞–≤—Ç–æ—Ä–∞",
        "–ø–æ—à–∞–≥–æ–≤—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è",
        "–ø—Ä–∏–º–µ—Ä—ã –∏ –∫–µ–π—Å—ã –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è",
        "—Å–∏–ª—å–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã –∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏",
        "–¥–ª—è –∫–æ–≥–æ –∫–Ω–∏–≥–∞ –∏ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª—ã",
    ]
    chunks, seen = [], set()
    for q in queries:
        for ch in search_book(book_id, q, top_k=10):
            t = (ch.get("text") or "").strip()
            if t and t not in seen:
                seen.add(t); chunks.append(t)
            if len(chunks) >= 60:
                break
        if len(chunks) >= 60:
            break
    joined = "\n\n".join(chunks)
    return joined[:40_000] if len(joined) > 40_000 else joined

# ---------- –ö–æ–Ω—Å–ø–µ–∫—Ç ----------

def _ask_json_summary(context: str, book_id: str, channel_name: str) -> Dict[str, Any]:
    system = "–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä –¥–µ–ª–æ–≤–æ–≥–æ Telegram-–∫–∞–Ω–∞–ª–∞. –°–¥–µ–ª–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –ø—Ä–∏–∫–ª–∞–¥–Ω–æ–π –∫–æ–Ω—Å–ø–µ–∫—Ç –∫–Ω–∏–≥–∏. –†—É—Å—Å–∫–∏–π —è–∑—ã–∫."
    user = f"""
–ù–∞ –≤—Ö–æ–¥–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∫–Ω–∏–≥–∏. –°–¥–µ–ª–∞–π JSON-–∫–æ–Ω—Å–ø–µ–∫—Ç:

{{
  "about": {{"title":"","author":"","thesis":"","audience":""}},
  "key_ideas": ["..."],
  "practices": [{{"name":"","steps":["—à–∞–≥ 1","—à–∞–≥ 2"]}}],
  "cases": ["..."],
  "quotes": [{{"text":"","note":""}}],
  "reflection": ["..."]
}}

–¢–æ—á–Ω–æ—Å—Ç—å –≤–∞–∂–Ω–µ–µ —Ñ–∞–Ω—Ç–∞–∑–∏–∏: –µ—Å–ª–∏ —Ñ–∞–∫—Ç–∞ –Ω–µ—Ç ‚Äî –æ—Å—Ç–∞–≤—å –ø–æ–ª–µ –ø—É—Å—Ç—ã–º.
–í–æ–∑–≤—Ä–∞—â–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π.

–§—Ä–∞–≥–º–µ–Ω—Ç—ã:
---
{context}
---
"""
    resp = _client().chat.completions.create(
        model=MODEL_SUMMARY,
        messages=[{"role":"system","content":system},
                  {"role":"user","content":user}],
        temperature=0.2,
        response_format={"type":"json_object"},
    )
    try:
        return json.loads(resp.choices[0].message.content)
    except Exception:
        return {
            "about":{"title":"","author":"","thesis":"","audience":""},
            "key_ideas":[],"practices":[],"cases":[],"quotes":[],"reflection":[]
        }

def _ensure_summary(book_id: str, channel_name: str) -> Dict[str, Any]:
    if book_id in _SUMMARY_CACHE:
        return _SUMMARY_CACHE[book_id]
    ctx = _collect_context(book_id)
    summary = _ask_json_summary(ctx, book_id, channel_name)
    _SUMMARY_CACHE[book_id] = summary
    return summary

# ---------- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–æ–≤ ----------

def _gen_with_prompt(fmt: str, summary: Dict[str, Any], *, book_id: str, channel_name: str) -> str:
    base = json.dumps(summary, ensure_ascii=False, indent=2)
    title = _book_title(summary, book_id, channel_name)
    author = _book_author(summary, book_id)

    prompts = {
        "announce": (
            "–°–¥–µ–ª–∞–π –∞–Ω–æ–Ω—Å –∫–Ω–∏–≥–∏ –¥–ª—è Telegram.\n"
            "–°—Ç—Ä—É–∫—Ç—É—Ä–∞:\n"
            "- 1 —Å—Ç—Ä–æ–∫–∞: –∑–∞—á–µ–º —á–∏—Ç–∞—Ç—å (–±–µ–∑ —Å–ª–æ–≤ ¬´—ç—Ç–∞ –∫–Ω–∏–≥–∞ –ø–æ–∫–∞–∂–µ—Ç¬ª),\n"
            "- 2‚Äì3 –±—É–ª–ª–µ—Ç–∞: –∫–æ–º—É –ø–æ–ª–µ–∑–Ω–æ/–∫–∞–∫–æ–π –≤—ã–∏–≥—Ä—ã—à,\n"
            "- 1 –∫—Ä—é—á–æ–∫: —è—Ä–∫–∞—è —Ü–∏—Ñ—Ä–∞/—Ñ–∞–∫—Ç/–º–µ—Ç–∞—Ñ–æ—Ä–∞.\n"
            "–°—Ç–∏–ª—å: —ç–Ω–µ—Ä–≥–∏—á–Ω–æ, –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ, –±–µ–∑ –≤–æ–¥—ã, 2‚Äì3 —É–º–µ—Å—Ç–Ω—ã—Ö —ç–º–æ–¥–∑–∏.\n"
            "–ò–∑–±–µ–≥–∞–π –æ–±—â–∏—Ö —Ñ—Ä–∞–∑ –≤—Ä–æ–¥–µ ¬´–≤ –æ–¥–Ω–æ–π –∏–∑ –≥–ª–∞–≤ –∞–≤—Ç–æ—Ä —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç¬ª. –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –Ω–∞–∑–≤–∞–Ω–∏–µ ‚Äî –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–±–∞–≤–∏–º –æ—Ç–¥–µ–ª—å–Ω–æ. –ë–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ (**)."
        ),
        "insight": (
            "–í—ã–¥–µ–ª–∏ 3‚Äì5 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∏–¥–µ–π –∏–∑ –∫–Ω–∏–≥–∏. –ö–∞–∂–¥–∞—è ‚Äî 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è + –∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–∏–∫–ª–∞–¥–Ω–æ–π –ø—Ä–∏–º–µ—Ä.\n"
            "–°—Ç–∏–ª—å: –ª–∞–∫–æ–Ω–∏—á–Ω–æ, —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ, 1‚Äì2 —ç–º–æ–¥–∑–∏ —Å—É–º–º–∞—Ä–Ω–æ. –ë–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ. –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–±–∞–≤–∏–º —Å–∞–º–∏."
        ),
        "practice": (
            "–í–æ–∑—å–º–∏ 1 –ø—Ä–∏–∫–ª–∞–¥–Ω—É—é –ø—Ä–∞–∫—Ç–∏–∫—É. –î–∞–π –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ 3‚Äì6 —á—ë—Ç–∫–∏—Ö —à–∞–≥–æ–≤.\n"
            "–î–æ–±–∞–≤—å –±—ã—Ç–æ–≤–æ–π –ø—Ä–∏–º–µ—Ä (–æ–¥–Ω–∏–º –∞–±–∑–∞—Ü–µ–º).\n"
            "–°—Ç–∏–ª—å: –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π, –±–µ–∑ –≤–æ–¥—ã, 1‚Äì2 —ç–º–æ–¥–∑–∏. –ë–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ. –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–±–∞–≤–∏–º —Å–∞–º–∏."
        ),
        "case": (
            "–û–ø–∏—à–∏ 1 –∫–µ–π—Å: –∫–æ–Ω—Ç–µ–∫—Å—Ç ‚Üí –¥–µ–π—Å—Ç–≤–∏–µ ‚Üí —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—Å —Ü–∏—Ñ—Ä–æ–π, –µ—Å–ª–∏ –µ—Å—Ç—å) ‚Üí –≤—ã–≤–æ–¥ (3‚Äì5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π).\n"
            "–ë–µ–∑ –æ–±—â–∏—Ö —à—Ç–∞–º–ø–æ–≤, 0‚Äì1 —ç–º–æ–¥–∑–∏. –ë–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ. –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–±–∞–≤–∏–º —Å–∞–º–∏."
        ),
        "quote": (
            "–î–∞–π 1 —Å–∏–ª—å–Ω—É—é —Ü–∏—Ç–∞—Ç—É –¥–æ—Å–ª–æ–≤–Ω–æ –≤ –∫–∞–≤—ã—á–∫–∞—Ö + 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è ¬´–∫–∞–∫ –ø—Ä–∏–º–µ–Ω–∏—Ç—å¬ª.\n"
            "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∞–≤—Ç–æ—Ä–∞. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Å–ø–µ–∫—Ç–µ –µ—Å—Ç—å –∞–≤—Ç–æ—Ä ‚Äî –æ–Ω –±—É–¥–µ—Ç —É–∫–∞–∑–∞–Ω –æ—Ç–¥–µ–ª—å–Ω–æ. –ë–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ, 0‚Äì1 —ç–º–æ–¥–∑–∏."
        ),
        "reflect": (
            "–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π 1‚Äì2 –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ —Ç–∞–∫, —á—Ç–æ–±—ã —á–∏—Ç–∞—Ç–µ–ª—å –ø—Ä–∏–º–µ—Ä–∏–ª –∏–¥–µ—é –Ω–∞ —Å–µ–±—è.\n"
            "–ö–æ—Ä–æ—Ç–∫–æ, 0‚Äì1 —ç–º–æ–¥–∑–∏. –ë–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ. –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–±–∞–≤–∏–º —Å–∞–º–∏."
        ),
    }
    prompt = prompts.get(fmt, "–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫—É—é –≤—ã–∂–∏–º–∫—É –ø–æ –∫–Ω–∏–≥–µ: –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ, –±–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ –∏ –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞.")

    resp = _client().chat.completions.create(
        model=MODEL_POSTS,
        messages=[
            {"role":"system","content":"–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä Telegram-–∫–∞–Ω–∞–ª–∞: –ø–∏—à–∏ —è—Ä–∫–æ, –ø–æ –¥–µ–ª—É, —Å –ª—ë–≥–∫–∏–º–∏ —ç–º–æ–¥–∑–∏ –∏ –±–µ–∑ –∂–∏—Ä–Ω–æ–≥–æ –≤—ã–¥–µ–ª–µ–Ω–∏—è."},
            {"role":"user","content":f"–ö–æ–Ω—Å–ø–µ–∫—Ç –∫–Ω–∏–≥–∏:\n{base}\n\n–ó–∞–¥–∞—á–∞:\n{prompt}"}
        ],
        temperature=0.7,
    )
    body = resp.choices[0].message.content or ""
    body = _normalize(body)
    body = _declickbait(body)
    body = _beautify_quotes(body)

    # –õ–∏–º–∏—Ç —ç–º–æ–¥–∑–∏ –ø–æ –¥–ª–∏–Ω–µ
    max_emoji = _emoji_budget_for_length(body)
    body = _limit_emojis(body, max_emoji)

    # –ó–∞–≥–æ–ª–æ–≤–∫–∏/—Ö—ç—à—Ç–µ–≥–∏
    map_emoji = {
        "announce": "üìö",
        "insight":  "üí°",
        "practice": "üõ†Ô∏è",
        "case":     "üìå",
        "quote":    "üó£Ô∏è",
        "reflect":  "üß≠",
    }
    map_tag = {
        "announce": "#–∞–Ω–æ–Ω—Å #–∫–Ω–∏–≥–∞",
        "insight":  "#–∏–Ω—Å–∞–π—Ç",
        "practice": "#–ø—Ä–∞–∫—Ç–∏–∫–∞",
        "case":     "#–∫–µ–π—Å",
        "quote":    "#—Ü–∏—Ç–∞—Ç–∞",
        "reflect":  "#—Ä–µ—Ñ–ª–µ–∫—Å–∏—è",
    }
    map_label = {
        "announce": "–∞–Ω–æ–Ω—Å",
        "insight":  "–∫–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏",
        "practice": "–ø—Ä–∞–∫—Ç–∏–∫–∞",
        "case":     "–∫–µ–π—Å",
        "quote":    "—Ü–∏—Ç–∞—Ç–∞",
        "reflect":  "–≤–æ–ø—Ä–æ—Å –¥–Ω—è",
    }

    emoji = map_emoji.get(fmt, "üìù")
    label = map_label.get(fmt, fmt)
    tags  = map_tag.get(fmt, "#—Å–≤–æ–¥–∫–∞")

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    if fmt == "announce":
        title_full = f"{title} ({author})" if author else title
        header = f"{emoji} –ö–Ω–∏–≥–∞ –¥–Ω—è ‚Äî {title_full}"
    else:
        header = f"{emoji} {title} ‚Äî {label.capitalize()}"

    # –î–ª—è —Ü–∏—Ç–∞—Ç—ã ‚Äî –∞–∫–∫—É—Ä–∞—Ç–Ω–∞—è –∞—Ç—Ä–∏–±—É—Ü–∏—è –∞–≤—Ç–æ—Ä–∞, –µ—Å–ª–∏ –æ–Ω –∏–∑–≤–µ—Å—Ç–µ–Ω –∏ –Ω–µ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ —Ç–µ–∫—Å—Ç–µ
    if fmt == "quote" and author:
        # –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ —É–∂–µ –µ—Å—Ç—å –¥–ª–∏–Ω–Ω–æ–µ —Ç–∏—Ä–µ + —á—Ç–æ-—Ç–æ –ø–æ—Ö–æ–∂–µ–µ –Ω–∞ –∏–º—è ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if not re.search(r"‚Äî\s*[A-Za-z–ê-–Ø–∞-—è–Å—ë][^\n]{1,60}$", body, flags=re.M):
            body = re.sub(r'(?s)^(¬´.*?¬ª|"[^"]{3,200}")', r"\1 ‚Äî " + author, body)

    final = f"{header}\n\n{body}\n\n{tags}"
    return final.strip()

# ---------- –ü—É–±–ª–∏—á–Ω—ã–µ ----------

def generate_from_book(channel_name: str, book_id: str, fmt: str) -> str:
    s = _ensure_summary(book_id, channel_name)
    return _gen_with_prompt(fmt.lower(), s, book_id=book_id, channel_name=channel_name)

def generate_by_format(fmt: str, items: List[dict]) -> str:
    f = (fmt or "").lower()
    if f == "quote":
        return "¬´–í—ã ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–æ–≥–æ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç–µ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å¬ª. #—Ü–∏—Ç–∞—Ç–∞"
    if f == "practice":
        return "–ü—Ä–∞–∫—Ç–∏–∫–∞ –Ω–µ–¥–µ–ª–∏: –ø—Ä–∞–≤–∏–ª–æ 2 –º–∏–Ω—É—Ç. #–ø—Ä–∞–∫—Ç–∏–∫–∞"
    return "–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –≥–æ—Ç–æ–≤—è—Ç—Å—è. #—Å–≤–æ–¥–∫–∞"

def get_author_for_book(book_id: str, channel_name: str) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–≤—Ç–æ—Ä–∞ –∫–Ω–∏–≥–∏: —Å–ø–µ—Ä–≤–∞ –∏–∑ –∫–æ–Ω—Å–ø–µ–∫—Ç–∞, –∑–∞—Ç–µ–º –∏–∑ –ª–∏—Å—Ç–∞ books."""
    summary = _ensure_summary(book_id, channel_name)
    return _book_author(summary, book_id)
