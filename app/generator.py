# app/generator.py
from __future__ import annotations

import os
from typing import Dict, List, Any

from app.retriever import search_book
from app.gpt import client  # –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–≥–æ –∂–µ –∫–ª–∏–µ–Ω—Ç–∞, —á—Ç–æ –∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤

# –ú–æ–¥–µ–ª—å –¥–ª—è –∫–æ–Ω—Å–ø–µ–∫—Ç–∞ –∏ –ø–æ—Å—Ç–æ–≤ (–º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤ Config Vars: OPENAI_MODEL_SUMMARY)
MODEL_SUMMARY = os.getenv("OPENAI_MODEL_SUMMARY", "gpt-4o-mini")
MODEL_POSTS   = os.getenv("OPENAI_MODEL_POSTS",   "gpt-4o-mini")

# –ü–∞–º—è—Ç–∫–∞ –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å (—á—Ç–æ–±—ã –Ω–µ –≥–æ–Ω—è—Ç—å –∫–æ–Ω—Å–ø–µ–∫—Ç –¥–ª—è –æ–¥–Ω–æ–π –∫–Ω–∏–≥–∏ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫—É —Ä–∞–∑)
_SUMMARY_CACHE: Dict[str, Dict[str, Any]] = {}


def _collect_context(book_id: str) -> str:
    """
    –ó–∞–±–∏—Ä–∞–µ–º ¬´—Å—ã—Ä—å—ë¬ª –∏–∑ –∫–Ω–∏–≥–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ü–µ–ª–µ–≤—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏.
    –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ 30‚Äì50 –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ (–º–æ–¥–µ–ª—å —Å–∞–º–∞ –∞–≥—Ä–µ–≥–∏—Ä—É–µ—Ç).
    """
    queries = [
        "–æ—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è –∫–Ω–∏–≥–∏ –≤ —Ü–µ–ª–æ–º",
        "–∫–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –∏ –ø—Ä–∞–≤–∏–ª–∞ –∞–≤—Ç–æ—Ä–∞",
        "–ø–æ—à–∞–≥–æ–≤—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è",
        "–ø—Ä–∏–º–µ—Ä—ã –∏ –∫–µ–π—Å—ã –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è",
        "—Å–∏–ª—å–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã –∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏",
        "–¥–ª—è –∫–æ–≥–æ –∫–Ω–∏–≥–∞ –∏ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª—ã",
    ]
    chunks: List[str] = []
    seen = set()

    for q in queries:
        for ch in search_book(book_id, q, top_k=10):
            t = (ch.get("text") or "").strip()
            if t and t not in seen:
                seen.add(t)
                chunks.append(t)
            if len(chunks) >= 60:
                break
        if len(chunks) >= 60:
            break

    # –°–∏–ª—å–Ω–∞—è —É—Å–µ—á–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤)
    joined = "\n\n".join(chunks)
    if len(joined) > 40_000:
        joined = joined[:40_000]
    return joined


def _ask_json_summary(context: str, book_id: str, channel_name: str) -> Dict[str, Any]:
    """
    –ü—Ä–æ—Å–∏–º –º–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É—Ç—å –°–¢–†–û–ì–û —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON‚Äë–∫–æ–Ω—Å–ø–µ–∫—Ç.
    """
    system = (
        "–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä –¥–µ–ª–æ–≤–æ–≥–æ –∫–∞–Ω–∞–ª–∞. –î–µ–ª–∞–µ—à—å –∫–æ—Ä–æ—Ç–∫–∏–π, —Ç–æ—á–Ω—ã–π, –ø—Ä–∏–∫–ª–∞–¥–Ω–æ–π –∫–æ–Ω—Å–ø–µ–∫—Ç –∫–Ω–∏–≥–∏. "
        "–ü–∏—à–∏ –ø—Ä–æ—Å—Ç–æ, –±–µ–∑ –≤–æ–¥—ã, –∏–∑–±–µ–≥–∞–π –æ–±—â–∏—Ö —Å–ª–æ–≤. –†—É—Å—Å–∫–∏–π —è–∑—ã–∫."
    )
    user = f"""
–£ —Ç–µ–±—è –Ω–∞ –≤—Ö–æ–¥–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑ –∫–Ω–∏–≥–∏ (–Ω–∏–∂–µ). –°–¥–µ–ª–∞–π –µ–¥–∏–Ω—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç –≤ JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–∞–Ω–∞–ª–æ–º ¬´{channel_name}¬ª.

–¢—Ä–µ–±—É–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ JSON (–∫–ª—é—á–∏ –∏–º–µ–Ω–Ω–æ —Ç–∞–∫–∏–µ):

{{
  "about": {{
    "title": "",           // –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å
    "author": "",          // –µ—Å–ª–∏ –µ—Å—Ç—å
    "thesis": "",          // –æ–¥–Ω–∞ —Ñ—Ä–∞–∑–∞ ‚Äî –∑–∞—á–µ–º –∫–Ω–∏–≥–∞
    "audience": ""         // –∫–æ–º—É –∏ –∫–æ–≥–¥–∞ –ø–æ–ª–µ–∑–Ω–∞
  }},
  "key_ideas": [           // 3‚Äì6 –∏–¥–µ–π, –∫–∞–∂–¥–∞—è 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    "‚Ä¶"
  ],
  "practices": [           // 2‚Äì4 –ø—Ä–∞–∫—Ç–∏–∫–∏, –∫–∞–∂–¥–∞—è: –∫–æ—Ä–æ—Ç–∫–∏–π –ø–æ—à–∞–≥–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º
    {{
      "name": "",
      "steps": ["—à–∞–≥ 1", "—à–∞–≥ 2"]
    }}
  ],
  "cases": [               // 1‚Äì3 –º–∏–Ω–∏‚Äë–∫–µ–π—Å–∞ –ø—Ä–∏–º–µ–Ω–∏—è –∏–¥–µ–∏ (–ø–æ 2‚Äì4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
    "‚Ä¶"
  ],
  "quotes": [              // 2‚Äì4 —Ü–∏—Ç–∞—Ç—ã: —Ç–æ—á–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ (–µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å)
    {{
      "text": "—Ü–∏—Ç–∞—Ç–∞",
      "note": "–∫—Ä–∞—Ç–∫–æ–µ –ø–æ—è—Å–Ω–µ–Ω–∏–µ"
    }}
  ],
  "reflection": [          // 2‚Äì3 –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏/—Ä–µ—Ñ–ª–µ–∫—Å–∏–∏
    "‚Ä¶"
  ]
}}

–ü—Ä–∞–≤–∏–ª–∞:
- –í–æ–∑–≤—Ä–∞—â–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π.
- –ï—Å–ª–∏ —á–µ–≥–æ-—Ç–æ –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ ‚Äî –æ—Å—Ç–∞–≤—å –ø–æ–ª–µ –ø—É—Å—Ç—ã–º/—Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç—ã–º, –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π.
- –°–æ—Ö—Ä–∞–Ω—è–π —Å–º—ã—Å–ª, –∏–∑–±–µ–≥–∞–π –ø–æ–≤—Ç–æ—Ä–æ–≤. –ö–æ—Ä–æ—Ç–∫–∏–µ, –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏.

–§—Ä–∞–≥–º–µ–Ω—Ç—ã –∏–∑ –∫–Ω–∏–≥–∏:
---
{context}
---
"""

    resp = client.chat.completions.create(
        model=MODEL_SUMMARY,
        messages=[
            {"role": "system", "content": system},
            {"role": "user",    "content": user},
        ],
        temperature=0.2,
        response_format={"type": "json_object"},
    )
    content = resp.choices[0].message.content
    import json
    try:
        data = json.loads(content)
    except Exception:
        # fallback: –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–∞—Ä–∫–∞—Å
        data = {
            "about": {"title": "", "author": "", "thesis": "", "audience": ""},
            "key_ideas": [],
            "practices": [],
            "cases": [],
            "quotes": [],
            "reflection": [],
        }
    return data


def _ensure_summary(book_id: str, channel_name: str) -> Dict[str, Any]:
    """
    –î–æ—Å—Ç–∞—ë–º –∫–æ–Ω—Å–ø–µ–∫—Ç –∏–∑ –∫—ç—à–∞ –∏–ª–∏ —Å—Ç—Ä–æ–∏–º –∑–∞–Ω–æ–≤–æ.
    (–ü–µ—Ä—Å–∏—Å—Ç –≤ –ë–î/—Ñ–∞–π–ª –¥–æ–±–∞–≤–∏–º –ø–æ–∑–∂–µ; –¥–ª—è Heroku –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—ç—à–∞ –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å.)
    """
    if book_id in _SUMMARY_CACHE:
        return _SUMMARY_CACHE[book_id]

    ctx = _collect_context(book_id)
    summary = _ask_json_summary(ctx, book_id, channel_name)
    _SUMMARY_CACHE[book_id] = summary
    return summary


# ---------- –†–µ–Ω–¥–µ—Ä—ã —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∏–∑ –∫–æ–Ω—Å–ø–µ–∫—Ç–∞ ----------

def _render_announce(s: Dict[str, Any]) -> str:
    about = s.get("about") or {}
    title = (about.get("title") or "").strip() or "–ö–Ω–∏–≥–∞ –¥–Ω—è"
    author = (about.get("author") or "").strip()
    thesis = (about.get("thesis") or "").strip()
    audience = (about.get("audience") or "").strip()

    bullets = []
    if thesis:
        bullets.append(f"‚Ä¢ –ó–∞—á–µ–º: {thesis}")
    if audience:
        bullets.append(f"‚Ä¢ –ö–æ–º—É: {audience}")
    ideas = s.get("key_ideas") or []
    if ideas:
        bullets.append(f"‚Ä¢ –í–Ω—É—Ç—Ä–∏: {min(len(ideas), 5)} –∫–ª—é—á–µ–≤—ã—Ö –∏–¥–µ–∏ –∏ –ø—Ä–∞–∫—Ç–∏–∫–∏")

    body = "\n".join(bullets[:3]) if bullets else ""
    by = f" ‚Äî {author}" if author else ""
    return f"üìö **{title}**{by}\n\n{body}\n\n#–∞–Ω–æ–Ω—Å #–∫–Ω–∏–≥–∞"


def _render_insight(s: Dict[str, Any]) -> str:
    ideas: List[str] = s.get("key_ideas") or []
    top = ideas[:5] if ideas else []
    if not top:
        return "3‚Äì5 –∏–¥–µ–π –∏–∑ –∫–Ω–∏–≥–∏: –º–∞—Ç–µ—Ä–∏–∞–ª—ã –≥–æ—Ç–æ–≤—è—Ç—Å—è. #–∏–Ω—Å–∞–π—Ç"
    lines = ["üí° **–ö–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏:**"]
    for i, it in enumerate(top, 1):
        lines.append(f"{i}. {it}")
    lines.append("\n#–∏–Ω—Å–∞–π—Ç")
    return "\n".join(lines)


def _render_practice(s: Dict[str, Any]) -> str:
    prs = s.get("practices") or []
    if not prs:
        return "–ü—Ä–∞–∫—Ç–∏–∫–∞ –¥–Ω—è –ø–æ—è–≤–∏—Ç—Å—è –ø–æ–∑–∂–µ. #–ø—Ä–∞–∫—Ç–∏–∫–∞"
    p = prs[0]
    name = (p.get("name") or "–ü—Ä–∞–∫—Ç–∏–∫–∞ –¥–Ω—è").strip()
    steps: List[str] = p.get("steps") or []
    lines = [f"üõ†Ô∏è **{name}**"]
    for i, st in enumerate(steps[:8], 1):
        lines.append(f"{i}) {st}")
    lines.append("\n#–ø—Ä–∞–∫—Ç–∏–∫–∞")
    return "\n".join(lines)


def _render_case(s: Dict[str, Any]) -> str:
    cases: List[str] = s.get("cases") or []
    if not cases:
        return "–ö–µ–π—Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–¥–µ–∏ –¥–æ–±–∞–≤–∏–º –ø–æ–∑–∂–µ. #–∫–µ–π—Å"
    txt = cases[0]
    return f"üìå **–ö–µ–π—Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è:**\n{txt}\n\n#–∫–µ–π—Å"


def _render_quote(s: Dict[str, Any]) -> str:
    quotes: List[Dict[str, str]] = s.get("quotes") or []
    if not quotes:
        return "¬´–¶–∏—Ç–∞—Ç–∞ –¥–Ω—è –ø–æ—è–≤–∏—Ç—Å—è –ø–æ–∑–∂–µ.¬ª #—Ü–∏—Ç–∞—Ç–∞"
    q = quotes[0]
    t = (q.get("text") or "").strip()
    note = (q.get("note") or "").strip()
    extra = f"\n‚Äî {note}" if note else ""
    return f"¬´{t}¬ª{extra}\n\n#—Ü–∏—Ç–∞—Ç–∞"


def _render_reflect(s: Dict[str, Any]) -> str:
    qs: List[str] = s.get("reflection") or []
    if not qs:
        return "–í–æ–ø—Ä–æ—Å –Ω–∞ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–µ –ø–æ—è–≤–∏—Ç—Å—è –ø–æ–∑–∂–µ. #—Ä–µ—Ñ–ª–µ–∫—Å–∏—è"
    lines = ["üß≠ **–í–æ–ø—Ä–æ—Å –¥–Ω—è:**", qs[0]]
    if len(qs) > 1:
        lines += ["", "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ:", f"‚Äî {qs[1]}"]
    lines.append("\n#—Ä–µ—Ñ–ª–µ–∫—Å–∏—è")
    return "\n".join(lines)


# ---------- –ü—É–±–ª–∏—á–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ----------

def generate_from_book(channel_name: str, book_id: str, fmt: str) -> str:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∞, –ù–û
    –≤—Å–µ–≥–¥–∞ –æ–ø–∏—Ä–∞–µ—Ç—Å—è –Ω–∞ –µ–¥–∏–Ω—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç –∫–Ω–∏–≥–∏.
    """
    s = _ensure_summary(book_id, channel_name)
    f = (fmt or "").lower()
    if f == "announce":
        return _render_announce(s)
    if f == "insight":
        return _render_insight(s)
    if f == "practice":
        return _render_practice(s)
    if f == "case":
        return _render_case(s)
    if f == "quote":
        return _render_quote(s)
    if f == "reflect":
        return _render_reflect(s)
    # –¥–µ—Ñ–æ–ª—Ç ‚Äî —Å–≤–æ–¥–∫–∞ –∏–¥–µ–π
    return _render_insight(s)


def generate_by_format(fmt: str, items: List[dict]) -> str:
    """
    legacy-—Ö–µ–ª–ø–µ—Ä (–æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –µ—Å–ª–∏ –≥–¥–µ-—Ç–æ –∑–æ–≤—ë—Ç—Å—è).
    –°–µ–π—á–∞—Å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–∞–π–ø–ª–∞–π–Ω–µ, –Ω–æ –Ω–µ –º–µ—à–∞–µ—Ç.
    """
    f = (fmt or "").lower()
    if f == "quote":
        return "¬´–í—ã ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–æ–≥–æ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç–µ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å¬ª. #—Ü–∏—Ç–∞—Ç–∞"
    if f == "practice":
        return "–ü—Ä–∞–∫—Ç–∏–∫–∞ –Ω–µ–¥–µ–ª–∏: –ø—Ä–∞–≤–∏–ª–æ 2 –º–∏–Ω—É—Ç. #–ø—Ä–∞–∫—Ç–∏–∫–∞"
    # –±–∞–∑–æ–≤—ã–π –¥–∞–π–¥–∂–µ—Å—Ç –Ω–∞ —Å–ª—É—á–∞–π –ø—É—Å—Ç–æ–≥–æ –≤–≤–æ–¥–∞
    top = items[:5] if items else []
    if not top:
        return "–°–≤–µ–∂–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ø–æ–∫–∞ –Ω–µ—Ç. –ó–∞–≥–ª—è–Ω–∏—Ç–µ –ø–æ–∑–∂–µ üïê"
    def cut(s: str, n: int) -> str:
        return s if len(s) <= n else s[: max(0, n-1)] + "‚Ä¶"
    lines = ["5 –∏–¥–µ–π –∏–∑ –¥–Ω—è:"]
    for i, it in enumerate(top, 1):
        title = cut(it.get("title") or "(–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)", 120)
        link = it.get("link") or ""
        lines.append(f"{i}. {title}\n{link}")
    lines.append("\n#–¥–∞–π–¥–∂–µ—Å—Ç #—Å–≤–æ–¥–∫–∞")
    return "\n".join(lines)
