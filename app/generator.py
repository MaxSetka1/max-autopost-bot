from __future__ import annotations
from typing import List, Dict

# === –°–¢–ê–†–´–ï —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è RSS ===
def cut(s: str, n: int) -> str:
    return s if len(s) <= n else s[: max(0, n-1)] + "‚Ä¶"

def generate_summary5(items: List[Dict]) -> str:
    top = items[:5]
    if not top:
        return "–°–≤–µ–∂–∏—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ø–æ–∫–∞ –Ω–µ—Ç. –ó–∞–≥–ª—è–Ω–∏—Ç–µ –ø–æ–∑–∂–µ üïê"
    lines = ["5 –∏–¥–µ–π –∏–∑ –¥–Ω—è:"]
    for i, it in enumerate(top, 1):
        title = cut(it.get("title") or "(–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è)", 120)
        link = it.get("link") or ""
        lines.append(f"{i}. {title}\n{link}")
    lines.append("\n#–¥–∞–π–¥–∂–µ—Å—Ç #—Å–≤–æ–¥–∫–∞")
    return "\n".join(lines)

def generate_card(items: List[Dict]) -> str:
    if not items:
        return "–ú—ã—Å–ª—å –¥–Ω—è: –¥–µ–ª–∞–π—Ç–µ –º–∞–ª–µ–Ω—å–∫–∏–µ —à–∞–≥–∏ ‚Äî –∫–∞–∂–¥—ã–π –¥–µ–Ω—å. #–∫–∞—Ä—Ç–æ—á–∫–∞"
    it = items[0]
    title = it.get("title") or "–ú—ã—Å–ª—å –¥–Ω—è"
    link = it.get("link") or ""
    return f"–ú—ã—Å–ª—å –¥–Ω—è: {title}\n{link}\n\n#–∫–∞—Ä—Ç–æ—á–∫–∞"

def generate_practice() -> str:
    return "–ü—Ä–∞–∫—Ç–∏–∫–∞ –Ω–µ–¥–µ–ª–∏: –ø—Ä–∞–≤–∏–ª–æ 2 –º–∏–Ω—É—Ç. –ù–∞—á–Ω–∏—Ç–µ —Å –º–∞–ª–æ–≥–æ ‚Äî —Å–¥–µ–ª–∞–π—Ç–µ –∑–∞ 2 –º–∏–Ω—É—Ç—ã —Ç–æ, —á—Ç–æ –æ—Ç–∫–ª–∞–¥—ã–≤–∞–ª–∏. #–ø—Ä–∞–∫—Ç–∏–∫–∞"

def generate_quote() -> str:
    return "¬´–í—ã ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–æ–≥–æ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç–µ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å¬ª. #—Ü–∏—Ç–∞—Ç–∞"

def generate_by_format(fmt: str, items: List[Dict]) -> str:
    fmt = (fmt or "").lower()
    if fmt == "summary5":
        return generate_summary5(items)
    if fmt == "card":
        return generate_card(items)
    if fmt == "practice":
        return generate_practice()
    if fmt == "quote":
        return generate_quote()
    return generate_summary5(items)


# === –ù–û–í–û–ï: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑ –∫–Ω–∏–∂–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ ===
from pathlib import Path
import yaml
from app.gpt import chat
from app.retriever import search_book

ROOT = Path(__file__).resolve().parents[1]
TOV = yaml.safe_load((ROOT / "config" / "tov.yaml").read_text(encoding="utf-8"))

def _load_tov(channel: str, fmt: str) -> tuple[str, int]:
    ch = TOV["channels"].get(channel, {})
    tone = ch.get("tone", "")
    ff = ch.get("formats", {}).get(fmt, {})
    instr = ff.get("instructions", "")
    max_len = int(ff.get("max_len", 800))
    return (f"{tone}\n\n{instr}".strip(), max_len)

def generate_from_book(channel: str, book_id: str, fmt: str) -> str:
    prompts = {
        "quote": "–õ—É—á—à–∞—è –∫–æ—Ä–æ—Ç–∫–∞—è —Ü–∏—Ç–∞—Ç–∞/–º—ã—Å–ª—å –∞–≤—Ç–æ—Ä–∞ ‚Äî —ë–º–∫–æ –∏ —Ç–æ—á–Ω–æ",
        "core": "–ì–ª–∞–≤–Ω–∞—è –º—ã—Å–ª—å –∫–Ω–∏–≥–∏ ‚Äî —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ —Å—É—Ç–∏ –ø–æ–¥—Ö–æ–¥–∞",
        "insight": "–ü–æ—á–µ–º—É –ø–æ–¥—Ö–æ–¥ —Ä–∞–±–æ—Ç–∞–µ—Ç ‚Äî –ø—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏–¥–µ–∏",
        "practice": "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —à–∞–≥–∏/—á–µ–∫–ª–∏—Å—Ç –ø–æ –∫–Ω–∏–≥–µ",
    }
    query = prompts.get(fmt.lower(), "–ö–ª—é—á–µ–≤–∞—è –∏–¥–µ—è –∫–Ω–∏–≥–∏")
    chunks = search_book(book_id, query, top_k=5)
    joined = "\n\n---\n\n".join([c["text"] for c in chunks]) if chunks else ""
    tov, max_len = _load_tov(channel, fmt.lower())
    sys = ("–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä –∫–∞–Ω–∞–ª–∞. –ü–µ—Ä–µ–ø–∏—Å—ã–≤–∞–π —Å–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏, –±–µ–∑ –∫–æ–ø–∏–ø–∞—Å—Ç–∞ –¥–ª–∏–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤. "
           "–ù–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç–æ–≤ –≤–Ω–µ –∏—Å—Ö–æ–¥–Ω–∏–∫–∞. –°–æ–±–ª—é–¥–∞–π –ª–∏–º–∏—Ç –¥–ª–∏–Ω—ã.")
    usr = f"""–ö–∞–Ω–∞–ª: {channel}
–§–æ—Ä–º–∞—Ç: {fmt}
–ü—Ä–∞–≤–∏–ª–∞ —Å—Ç–∏–ª—è:
{tov}

–ò—Å—Ö–æ–¥–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã (–∏–∑ –∫–Ω–∏–≥–∏ {book_id}):
{joined}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ: –æ–¥–∏–Ω –≥–æ—Ç–æ–≤—ã–π –ø–æ—Å—Ç, –Ω–µ –±–æ–ª–µ–µ {max_len} —Å–∏–º–≤–æ–ª–æ–≤."""
    out = chat(sys, usr, max_tokens=900)
    return out[:max_len]
