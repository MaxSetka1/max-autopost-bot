# app/generator.py
from __future__ import annotations

import os
from typing import Dict, List, Any

from app.retriever import search_book
from app.gpt import client  # Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ‚Ğ¾Ğ³Ğ¾ Ğ¶Ğµ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°, Ñ‡Ñ‚Ğ¾ Ğ¸ Ğ´Ğ»Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²

# ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ ĞºĞ¾Ğ½ÑĞ¿ĞµĞºÑ‚Ğ° Ğ¸ Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ² (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿ĞµÑ€ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ğ² Config Vars: OPENAI_MODEL_SUMMARY)
MODEL_SUMMARY = os.getenv("OPENAI_MODEL_SUMMARY", "gpt-4o-mini")
MODEL_POSTS   = os.getenv("OPENAI_MODEL_POSTS",   "gpt-4o-mini")

# ĞŸĞ°Ğ¼ÑÑ‚ĞºĞ° Ğ½Ğ° Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ (Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğµ Ğ³Ğ¾Ğ½ÑÑ‚ÑŒ ĞºĞ¾Ğ½ÑĞ¿ĞµĞºÑ‚ Ğ´Ğ»Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ ĞºĞ½Ğ¸Ğ³Ğ¸ Ğ¿Ğ¾ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºÑƒ Ñ€Ğ°Ğ·)
_SUMMARY_CACHE: Dict[str, Dict[str, Any]] = {}


def _collect_context(book_id: str) -> str:
    """
    Ğ—Ğ°Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Â«ÑÑ‹Ñ€ÑŒÑ‘Â» Ğ¸Ğ· ĞºĞ½Ğ¸Ğ³Ğ¸ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ğ¼Ğ¸ Ñ†ĞµĞ»ĞµĞ²Ñ‹Ğ¼Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸.
    Ğ”Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ 30â€“50 ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² (Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ÑĞ°Ğ¼Ğ° Ğ°Ğ³Ñ€ĞµĞ³Ğ¸Ñ€ÑƒĞµÑ‚).
    """
    queries = [
        "Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ¸Ğ´ĞµÑ ĞºĞ½Ğ¸Ğ³Ğ¸ Ğ² Ñ†ĞµĞ»Ğ¾Ğ¼",
        "ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ñ‹ Ğ¸ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ° Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ°",
        "Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞ¸ Ğ¸ ÑƒĞ¿Ñ€Ğ°Ğ¶Ğ½ĞµĞ½Ğ¸Ñ",
        "Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¸ ĞºĞµĞ¹ÑÑ‹ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ",
        "ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ñ†Ğ¸Ñ‚Ğ°Ñ‚Ñ‹ Ğ¸ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸",
        "Ğ´Ğ»Ñ ĞºĞ¾Ğ³Ğ¾ ĞºĞ½Ğ¸Ğ³Ğ° Ğ¸ ĞºĞ°Ğº Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ñ‹",
    ]
    chunks: List[str] = []
    seen = set()

    for q in queries:
        for ch in search_book(book_id, q, top_k=10):
            t = (ch.get("text") or "").strip()
            if t and t not in seen:
                seen.add(t)
                chunks.append(t)
            if len(chunks) >= 60:
                break
        if len(chunks) >= 60:
            break

    # Ğ¡Ğ¸Ğ»ÑŒĞ½Ğ°Ñ ÑƒÑĞµÑ‡ĞºĞ° ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° (Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ Ğ´Ğ»Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²)
    joined = "\n\n".join(chunks)
    if len(joined) > 40_000:
        joined = joined[:40_000]
    return joined


def _ask_json_summary(context: str, book_id: str, channel_name: str) -> Dict[str, Any]:
    """
    ĞŸÑ€Ğ¾ÑĞ¸Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ Ğ¡Ğ¢Ğ ĞĞ“Ğ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ JSONâ€‘ĞºĞ¾Ğ½ÑĞ¿ĞµĞºÑ‚.
    """
    system = (
        "Ğ¢Ñ‹ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¾Ñ€ Ğ´ĞµĞ»Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ĞºĞ°Ğ½Ğ°Ğ»Ğ°. Ğ”ĞµĞ»Ğ°ĞµÑˆÑŒ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹, Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹, Ğ¿Ñ€Ğ¸ĞºĞ»Ğ°Ğ´Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ½ÑĞ¿ĞµĞºÑ‚ ĞºĞ½Ğ¸Ğ³Ğ¸. "
        "ĞŸĞ¸ÑˆĞ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾, Ğ±ĞµĞ· Ğ²Ğ¾Ğ´Ñ‹, Ğ¸Ğ·Ğ±ĞµĞ³Ğ°Ğ¹ Ğ¾Ğ±Ñ‰Ğ¸Ñ… ÑĞ»Ğ¾Ğ². Ğ ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº."
    )
    user = f"""
Ğ£ Ñ‚ĞµĞ±Ñ Ğ½Ğ° Ğ²Ñ…Ğ¾Ğ´Ğµ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸Ğ· ĞºĞ½Ğ¸Ğ³Ğ¸ (Ğ½Ğ¸Ğ¶Ğµ). Ğ¡Ğ´ĞµĞ»Ğ°Ğ¹ ĞµĞ´Ğ¸Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½ÑĞ¿ĞµĞºÑ‚ Ğ² JSON Ğ´Ğ»Ñ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞµĞ³Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ĞºĞ°Ğ½Ğ°Ğ»Ğ¾Ğ¼ Â«{channel_name}Â».

Ğ¢Ñ€ĞµĞ±ÑƒĞµĞ¼Ğ°Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° JSON (ĞºĞ»ÑÑ‡Ğ¸ Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ Ñ‚Ğ°ĞºĞ¸Ğµ):

{{
  "about": {{
    "title": "",           // ĞµÑĞ»Ğ¸ Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ ĞµÑÑ‚ÑŒ
    "author": "",          // ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
    "thesis": "",          // Ğ¾Ğ´Ğ½Ğ° Ñ„Ñ€Ğ°Ğ·Ğ° â€” Ğ·Ğ°Ñ‡ĞµĞ¼ ĞºĞ½Ğ¸Ğ³Ğ°
    "audience": ""         // ĞºĞ¾Ğ¼Ñƒ Ğ¸ ĞºĞ¾Ğ³Ğ´Ğ° Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ°
  }},
  "key_ideas": [           // 3â€“6 Ğ¸Ğ´ĞµĞ¹, ĞºĞ°Ğ¶Ğ´Ğ°Ñ 1â€“2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
    "â€¦"
  ],
  "practices": [           // 2â€“4 Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞ¸, ĞºĞ°Ğ¶Ğ´Ğ°Ñ: ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼
    {{
      "name": "",
      "steps": ["ÑˆĞ°Ğ³ 1", "ÑˆĞ°Ğ³ 2"]
    }}
  ],
  "cases": [               // 1â€“3 Ğ¼Ğ¸Ğ½Ğ¸â€‘ĞºĞµĞ¹ÑĞ° Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ñ Ğ¸Ğ´ĞµĞ¸ (Ğ¿Ğ¾ 2â€“4 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ)
    "â€¦"
  ],
  "quotes": [              // 2â€“4 Ñ†Ğ¸Ñ‚Ğ°Ñ‚Ñ‹: Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ (ĞµÑĞ»Ğ¸ Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ ĞµÑÑ‚ÑŒ)
    {{
      "text": "Ñ†Ğ¸Ñ‚Ğ°Ñ‚Ğ°",
      "note": "ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¿Ğ¾ÑÑĞ½ĞµĞ½Ğ¸Ğµ"
    }}
  ],
  "reflection": [          // 2â€“3 Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ° Ğ´Ğ»Ñ ÑĞ°Ğ¼Ğ¾Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸/Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ğ¸
    "â€¦"
  ]
}}

ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ°:
- Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°Ğ¹ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ JSON Ğ±ĞµĞ· Ğ¿Ğ¾ÑÑĞ½ĞµĞ½Ğ¸Ğ¹.
- Ğ•ÑĞ»Ğ¸ Ñ‡ĞµĞ³Ğ¾-Ñ‚Ğ¾ Ğ½ĞµÑ‚ Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ â€” Ğ¾ÑÑ‚Ğ°Ğ²ÑŒ Ğ¿Ğ¾Ğ»Ğµ Ğ¿ÑƒÑÑ‚Ñ‹Ğ¼/ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¿ÑƒÑÑ‚Ñ‹Ğ¼, Ğ½Ğµ Ğ²Ñ‹Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ğ¹.
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞ¹ ÑĞ¼Ñ‹ÑĞ», Ğ¸Ğ·Ğ±ĞµĞ³Ğ°Ğ¹ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ². ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ, Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸.

Ğ¤Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸Ğ· ĞºĞ½Ğ¸Ğ³Ğ¸:
---
{context}
---
"""

    resp = client.chat.completions.create(
        model=MODEL_SUMMARY,
        messages=[
            {"role": "system", "content": system},
            {"role": "user",    "content": user},
        ],
        temperature=0.2,
        response_format={"type": "json_object"},
    )
    content = resp.choices[0].message.content
    import json
    try:
        data = json.loads(content)
    except Exception:
        # fallback: Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ°Ñ€ĞºĞ°Ñ
        data = {
            "about": {"title": "", "author": "", "thesis": "", "audience": ""},
            "key_ideas": [],
            "practices": [],
            "cases": [],
            "quotes": [],
            "reflection": [],
        }
    return data


def _ensure_summary(book_id: str, channel_name: str) -> Dict[str, Any]:
    """
    Ğ”Ğ¾ÑÑ‚Ğ°Ñ‘Ğ¼ ĞºĞ¾Ğ½ÑĞ¿ĞµĞºÑ‚ Ğ¸Ğ· ĞºÑÑˆĞ° Ğ¸Ğ»Ğ¸ ÑÑ‚Ñ€Ğ¾Ğ¸Ğ¼ Ğ·Ğ°Ğ½Ğ¾Ğ²Ğ¾.
    (ĞŸĞµÑ€ÑĞ¸ÑÑ‚ Ğ² Ğ‘Ğ”/Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ğ¼ Ğ¿Ğ¾Ğ·Ğ¶Ğµ; Ğ´Ğ»Ñ Heroku Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ ĞºÑÑˆĞ° Ğ½Ğ° Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ.)
    """
    if book_id in _SUMMARY_CACHE:
        return _SUMMARY_CACHE[book_id]

    ctx = _collect_context(book_id)
    summary = _ask_json_summary(ctx, book_id, channel_name)
    _SUMMARY_CACHE[book_id] = summary
    return summary


# ---------- Ğ ĞµĞ½Ğ´ĞµÑ€Ñ‹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¾Ğ² Ğ¸Ğ· ĞºĞ¾Ğ½ÑĞ¿ĞµĞºÑ‚Ğ° ----------

def _render_announce(s: Dict[str, Any]) -> str:
    about = s.get("about") or {}
    title = (about.get("title") or "").strip() or "ĞšĞ½Ğ¸Ğ³Ğ° Ğ´Ğ½Ñ"
    author = (about.get("author") or "").strip()
    thesis = (about.get("thesis") or "").strip()
    audience = (about.get("audience") or "").strip()

    bullets = []
    if thesis:
        bullets.append(f"â€¢ Ğ—Ğ°Ñ‡ĞµĞ¼: {thesis}")
    if audience:
        bullets.append(f"â€¢ ĞšĞ¾Ğ¼Ñƒ: {audience}")
    ideas = s.get("key_ideas") or []
    if ideas:
        bullets.append(f"â€¢ Ğ’Ğ½ÑƒÑ‚Ñ€Ğ¸: {min(len(ideas), 5)} ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… Ğ¸Ğ´ĞµĞ¸ Ğ¸ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞ¸")

    body = "\n".join(bullets[:3]) if bullets else ""
    by = f" â€” {author}" if author else ""
    return f"ğŸ“š **{title}**{by}\n\n{body}\n\n#Ğ°Ğ½Ğ¾Ğ½Ñ #ĞºĞ½Ğ¸Ğ³Ğ°"


def _render_insight(s: Dict[str, Any]) -> str:
    ideas: List[str] = s.get("key_ideas") or []
    top = ideas[:5] if ideas else []
    if not top:
        return "3â€“5 Ğ¸Ğ´ĞµĞ¹ Ğ¸Ğ· ĞºĞ½Ğ¸Ğ³Ğ¸: Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ñ‹ Ğ³Ğ¾Ñ‚Ğ¾Ğ²ÑÑ‚ÑÑ. #Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚"
    lines = ["ğŸ’¡ **ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¸Ğ´ĞµĞ¸:**"]
    for i, it in enumerate(top, 1):
        lines.append(f"{i}. {it}")
    lines.append("\n#Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚")
    return "\n".join(lines)


def _render_practice(s: Dict[str, Any]) -> str:
    prs = s.get("practices") or []
    if not prs:
        return "ĞŸÑ€Ğ°ĞºÑ‚Ğ¸ĞºĞ° Ğ´Ğ½Ñ Ğ¿Ğ¾ÑĞ²Ğ¸Ñ‚ÑÑ Ğ¿Ğ¾Ğ·Ğ¶Ğµ. #Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞ°"
    p = prs[0]
    name = (p.get("name") or "ĞŸÑ€Ğ°ĞºÑ‚Ğ¸ĞºĞ° Ğ´Ğ½Ñ").strip()
    steps: List[str] = p.get("steps") or []
    lines = [f"ğŸ› ï¸ **{name}**"]
    for i, st in enumerate(steps[:8], 1):
        lines.append(f"{i}) {st}")
    lines.append("\n#Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞ°")
    return "\n".join(lines)


def _render_case(s: Dict[str, Any]) -> str:
    cases: List[str] = s.get("cases") or []
    if not cases:
        return "ĞšĞµĞ¹Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ¸Ğ´ĞµĞ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ğ¼ Ğ¿Ğ¾Ğ·Ğ¶Ğµ. #ĞºĞµĞ¹Ñ"
    txt = cases[0]
    return f"ğŸ“Œ **ĞšĞµĞ¹Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ:**\n{txt}\n\n#ĞºĞµĞ¹Ñ"


def _render_quote(s: Dict[str, Any]) -> str:
    quotes: List[Dict[str, str]] = s.get("quotes") or []
    if not quotes:
        return "Â«Ğ¦Ğ¸Ñ‚Ğ°Ñ‚Ğ° Ğ´Ğ½Ñ Ğ¿Ğ¾ÑĞ²Ğ¸Ñ‚ÑÑ Ğ¿Ğ¾Ğ·Ğ¶Ğµ.Â» #Ñ†Ğ¸Ñ‚Ğ°Ñ‚Ğ°"
    q = quotes[0]
    t = (q.get("text") or "").strip()
    note = (q.get("note") or "").strip()
    extra = f"\nâ€” {note}" if note else ""
    return f"Â«{t}Â»{extra}\n\n#Ñ†Ğ¸Ñ‚Ğ°Ñ‚Ğ°"


def _render_reflect(s: Dict[str, Any]) -> str:
    qs: List[str] = s.get("reflection") or []
    if not qs:
        return "Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ²Ğ¸Ñ‚ÑÑ Ğ¿Ğ¾Ğ·Ğ¶Ğµ. #Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ñ"
    lines = ["ğŸ§­ **Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ´Ğ½Ñ:**", qs[0]]
    if len(qs) > 1:
        lines += ["", "Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾:", f"â€” {qs[1]}"]
    lines.append("\n#Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ñ")
    return "\n".join(lines)


# ---------- ĞŸÑƒĞ±Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ ----------

def generate_from_book(channel_name: str, book_id: str, fmt: str) -> str:
    """
    Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ‚Ğ¾Ñ‡ĞºĞ°: Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°, ĞĞ
    Ğ²ÑĞµĞ³Ğ´Ğ° Ğ¾Ğ¿Ğ¸Ñ€Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° ĞµĞ´Ğ¸Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½ÑĞ¿ĞµĞºÑ‚ ĞºĞ½Ğ¸Ğ³Ğ¸.
    """
    s = _ensure_summary(book_id, channel_name)
    f = (fmt or "").lower()
    if f == "announce":
        return _render_announce(s)
    if f == "insight":
        return _render_insight(s)
    if f == "practice":
        return _render_practice(s)
    if f == "case":
        return _render_case(s)
    if f == "quote":
        return _render_quote(s)
    if f == "reflect":
        return _render_reflect(s)
    # Ğ´ĞµÑ„Ğ¾Ğ»Ñ‚ â€” ÑĞ²Ğ¾Ğ´ĞºĞ° Ğ¸Ğ´ĞµĞ¹
    return _render_insight(s)


def generate_by_format(fmt: str, items: List[dict]) -> str:
    """
    legacy-Ñ…ĞµĞ»Ğ¿ĞµÑ€ (Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸, ĞµÑĞ»Ğ¸ Ğ³Ğ´Ğµ-Ñ‚Ğ¾ Ğ·Ğ¾Ğ²Ñ‘Ñ‚ÑÑ).
    Ğ¡ĞµĞ¹Ñ‡Ğ°Ñ Ğ½Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ² Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¼ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğµ, Ğ½Ğ¾ Ğ½Ğµ Ğ¼ĞµÑˆĞ°ĞµÑ‚.
    """
    f = (fmt or "").lower()
    if f == "quote":
        return "Â«Ğ’Ñ‹ â€” Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚Ğ¾Ğ³Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°ĞµÑ‚Ğµ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ´ĞµĞ½ÑŒÂ». #Ñ†Ğ¸Ñ‚Ğ°Ñ‚Ğ°"
    if f == "practice":
        return "ĞŸÑ€Ğ°ĞºÑ‚Ğ¸ĞºĞ° Ğ½ĞµĞ´ĞµĞ»Ğ¸: Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¾ 2 Ğ¼Ğ¸Ğ½ÑƒÑ‚. #Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞ°"
    # Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ Ğ´Ğ°Ğ¹Ğ´Ğ¶ĞµÑÑ‚ Ğ½Ğ° ÑĞ»ÑƒÑ‡Ğ°Ğ¹ Ğ¿ÑƒÑÑ‚Ğ¾Ğ³Ğ¾ Ğ²Ğ²Ğ¾Ğ´Ğ°
    top = items[:5] if items else []
    if not top:
        return "Ğ¡Ğ²ĞµĞ¶Ğ¸Ñ… Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ğ¾Ğ² Ğ¿Ğ¾ĞºĞ° Ğ½ĞµÑ‚. Ğ—Ğ°Ğ³Ğ»ÑĞ½Ğ¸Ñ‚Ğµ Ğ¿Ğ¾Ğ·Ğ¶Ğµ ğŸ•"
    def cut(s: str, n: int) -> str:
        return s if len(s) <= n else s[: max(0, n-1)] + "â€¦"
    lines = ["5 Ğ¸Ğ´ĞµĞ¹ Ğ¸Ğ· Ğ´Ğ½Ñ:"]
    for i, it in enumerate(top, 1):
        title = cut(it.get("title") or "(Ğ±ĞµĞ· Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ)", 120)
        link = it.get("link") or ""
        lines.append(f"{i}. {title}\n{link}")
    lines.append("\n#Ğ´Ğ°Ğ¹Ğ´Ğ¶ĞµÑÑ‚ #ÑĞ²Ğ¾Ğ´ĞºĞ°")
    return "\n".join(lines)
